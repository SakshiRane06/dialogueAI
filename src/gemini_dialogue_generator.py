"""
Google Gemini Dialogue Generator Module

Alternative dialogue generator using Google's Gemini API instead of OpenAI.
"""

import os
from dataclasses import dataclass
from typing import Optional

import google.generativeai as genai
from rich.console import Console

console = Console()


@dataclass
class GeminiDialogueConfig:
    """Configuration for Gemini dialogue generation."""
    tone: str = "conversational"  # e.g., casual, academic, fun, formal
    level: str = "intermediate"   # e.g., beginner, intermediate, advanced
    max_turns: int = 16           # max back-and-forth turns (Learner/Expert)
    temperature: float = 0.7
    model_name: str = "gemini-pro"


class GeminiDialogueGenerator:
    """Generates dialogues using Google's Gemini API."""

    def __init__(self, config: Optional[GeminiDialogueConfig] = None, api_key: Optional[str] = None):
        self.config = config or GeminiDialogueConfig()
        
        # Configure Gemini API
        api_key = api_key or os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("Google API key is required. Set GOOGLE_API_KEY environment variable.")
        
        genai.configure(api_key=api_key)
        
        # Initialize the model
        try:
            self.model = genai.GenerativeModel(self.config.model_name)
            console.print(f"âœ… Gemini {self.config.model_name} initialized", style="green")
        except Exception as e:
            console.print(f"âŒ Failed to initialize Gemini: {e}", style="red")
            raise

    def generate(self, user_goal: str, context: str) -> str:
        """
        Generate dialogue using Gemini API.
        
        Args:
            user_goal: User's goal or request
            context: Retrieved context from RAG system
            
        Returns:
            Generated dialogue as string
        """
        console.print("ğŸ—£ï¸ Generating dialogue with Gemini...", style="blue")
        
        prompt = self._build_prompt(user_goal, context)
        
        try:
            # Generate response
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=self.config.temperature,
                    max_output_tokens=2000,
                )
            )
            
            if response.candidates and response.candidates[0].content.parts:
                dialogue = response.candidates[0].content.parts[0].text
                console.print("âœ… Dialogue generated successfully", style="green")
                return dialogue
            else:
                raise ValueError("No content generated by Gemini")
                
        except Exception as e:
            console.print(f"âŒ Error generating dialogue: {e}", style="red")
            raise

    def _build_prompt(self, user_goal: str, context: str) -> str:
        """Create a structured prompt for high-quality, grounded dialogue."""
        
        system_instructions = f"""
You are DialogueAI, tasked with crafting a clear, engaging two-person dialogue between a curious Learner (ğŸ‘¦ Learner) and a knowledgeable Expert (ğŸ‘¨ Expert). The dialogue must be grounded in the provided CONTEXT.

Guidelines:
- Tone: {self.config.tone}
- Difficulty: {self.config.level}
- Max turns: {self.config.max_turns} (each turn is a pair: Learner then Expert)
- Prefer short, natural utterances
- Encourage progressive disclosure: start broad, then deepen based on CONTEXT
- Explicitly cite references using [Source: <source>, Chunk <n>] when a point is taken from context
- If the context lacks information, say so briefly and avoid fabricating details
- Output MUST strictly alternate speakers and start with the Learner
- Output format must be plain text like:
ğŸ‘¦ Learner: <line>
ğŸ‘¨ Expert: <line>
...
"""

        user_prompt = f"""
USER_GOAL:
{user_goal}

CONTEXT (use selectively and cite):
{context}

Produce the dialogue now.
"""
        
        return f"{system_instructions}\n\n{user_prompt}"


# Test function
def test_gemini_generator():
    """Test the Gemini dialogue generator."""
    try:
        generator = GeminiDialogueGenerator()
        
        test_context = """
        [Source: sample.txt, Chunk 1]
        Retrieval-Augmented Generation (RAG) is a powerful technique that combines the strengths of retrieval-based and generation-based approaches in natural language processing.
        
        [Source: sample.txt, Chunk 2]
        RAG operates in two main phases: 1. Retrieval Phase: When given a query or prompt, the system searches through a knowledge base to find relevant documents.
        """
        
        test_goal = "Explain what RAG is in simple terms"
        
        dialogue = generator.generate(test_goal, test_context)
        
        console.print("\nğŸ‰ [bold green]Generated Dialogue:[/bold green]")
        console.print(dialogue)
        
        return dialogue
        
    except Exception as e:
        console.print(f"âŒ Test failed: {e}", style="red")
        return None


if __name__ == "__main__":
    test_gemini_generator()
